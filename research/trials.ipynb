{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6ae7bfc",
   "metadata": {},
   "source": [
    "# performing \"research\" for the chatbot \n",
    "##### (RAG + safe Pandas function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5d2459",
   "metadata": {},
   "source": [
    "### Check to see if <b>jupyter notebook is running</b> and import the libaries needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "634db173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello World!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "665f98f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\chatbot\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import necessary libaries\n",
    "import os\n",
    "import pandas as pd\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from typing import List\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "from pinecone import Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from dateutil import parser\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39335c26",
   "metadata": {},
   "source": [
    "### move the working directory up to access data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ccc2c08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\User\\\\Downloads\\\\Personal Projects\\\\Generative AI Chatbot\\\\Building-a-Generative-AI-Chatbot-with-RAG\\\\research'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking working directory, moved it up by one so that the data folder is accessiable\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f969228e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\User\\\\Downloads\\\\Personal Projects\\\\Generative AI Chatbot\\\\Building-a-Generative-AI-Chatbot-with-RAG'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# moves working directory up\n",
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adcaba5",
   "metadata": {},
   "source": [
    "### data understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6c84b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Visit ID', 'Patient ID', 'Hospital ID', 'Hospital Name', 'Region',\n",
       "       'Visit Date', 'Day of Week', 'Season', 'Time of Day', 'Urgency Level',\n",
       "       'Nurse-to-Patient Ratio', 'Specialist Availability',\n",
       "       'Facility Size (Beds)', 'Time to Registration (min)',\n",
       "       'Time to Triage (min)', 'Time to Medical Professional (min)',\n",
       "       'Total Wait Time (min)', 'Patient Outcome', 'Patient Satisfaction'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the data \n",
    "df = pd.read_csv('data/ER Wait Time Dataset.csv')\n",
    "df[\"Visit Date\"] = pd.to_datetime(df[\"Visit Date\"])\n",
    "\n",
    "# check column names so that data can be rewritten and stored as document\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d4719f",
   "metadata": {},
   "source": [
    "### load <b> all data </b>from data folder (assuming consistent format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58715070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function loads multiple files from file_path and returns it as a whole \n",
    "def load_csv_files(file_path):\n",
    "    documents = []\n",
    "\n",
    "    for file in os.listdir(file_path):\n",
    "        if file.endswith(\".csv\"):\n",
    "            file_path = os.path.join(file_path, file)\n",
    "\n",
    "            df = pd.read_csv(file_path)\n",
    "            df[\"Visit Date\"] = pd.to_datetime(df[\"Visit Date\"], errors=\"coerce\")\n",
    "\n",
    "            # the conversion of data here is hard coded, assuming datasets in the folder have the same columns/format\n",
    "            for _, row in df.iterrows():\n",
    "                content = f\"\"\"\n",
    "                On {row['Visit Date']} at {row['Hospital Name']} (Region: {row['Region']}),\n",
    "                urgency level was {row['Urgency Level']}.\n",
    "                Total wait time was {row['Total Wait Time (min)']} minutes.\n",
    "                Patient outcome was {row['Patient Outcome']}.\n",
    "                Patient satisfaction was {row['Patient Satisfaction']}.\n",
    "                \"\"\"\n",
    "\n",
    "                documents.append(\n",
    "                    Document(\n",
    "                        page_content=content.strip(),\n",
    "                        metadata={\n",
    "                            \"source_file\": file,\n",
    "                            \"hospital\": row[\"Hospital Name\"],\n",
    "                            \"region\": row[\"Region\"]\n",
    "                        }\n",
    "                    )\n",
    "                )\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fcda3c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check length of data\n",
    "extracted_data = load_csv_files(\"data\")\n",
    "len(extracted_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5d8776",
   "metadata": {},
   "source": [
    "### <b>vector storing process</b> (in Pinecone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "326bd435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplify the data and standarize for vector storing\n",
    "\n",
    "def filter_to_minimal_docs(docs: List[Document]) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Given a list of document objects, return a new list of document objects\n",
    "    containing only 'source' in metadata and the original page_content.\n",
    "    \"\"\"\n",
    "    minimal_docs: List[Document] = []\n",
    "    for doc in docs:\n",
    "        src = doc.metadata.get(\"source_file\")\n",
    "\n",
    "        minimal_docs.append(\n",
    "            Document(\n",
    "                page_content=doc.page_content,\n",
    "                metadata={\"source\": src}\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return minimal_docs\n",
    "\n",
    "minimal_docs = filter_to_minimal_docs(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "591f6b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Chunks: 5000\n"
     ]
    }
   ],
   "source": [
    "# split the documents into smaller chunks\n",
    "def text_split(minimal_docs):\n",
    "    text_spliter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=20\n",
    "    )\n",
    "    text_chunks = text_spliter.split_documents(minimal_docs)\n",
    "    return text_chunks\n",
    "\n",
    "text_chunks = text_split(minimal_docs)\n",
    "print(f\"Number of Chunks: {len(text_chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e7e5994",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_14508\\1077763997.py:6: LangChainDeprecationWarning: The class `HuggingFaceBgeEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceBgeEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "def download_embeddings():\n",
    "    \"\"\"\n",
    "    Download and return the HuggingFace Embeddings model.\n",
    "    \"\"\"\n",
    "    model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    embeddings = HuggingFaceBgeEmbeddings(\n",
    "        model_name=model_name\n",
    "    )\n",
    "    return embeddings\n",
    "\n",
    "embedding = download_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4683822e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceBgeEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, query_instruction='Represent this question for searching relevant passages: ', embed_instruction='', show_progress=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dea6242c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in the needed API keys\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5da39d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53363fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign pinecone api key to variable pc\n",
    "pinecone_api_key = PINECONE_API_KEY\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20f8931e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating index into pinecone if not already present\n",
    "index_name = \"genai-chatbot\"\n",
    "\n",
    "if not pc.has_index(index_name):\n",
    "    pc.create_index(\n",
    "        name = index_name,\n",
    "        dimension = 384, # dimension of embeddings\n",
    "        metric = \"cosine\", # cosine similarity\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "    )\n",
    "\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3d74ce",
   "metadata": {},
   "source": [
    "if embeddings are already stored, <b>do not need to run the markdown code below</b>. <br>\n",
    "If not duplicated embeddings will be created"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4912bff5",
   "metadata": {},
   "source": [
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents = text_chunks,\n",
    "    embedding = embedding,\n",
    "    index_name = index_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b081172d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load existing index\n",
    "\n",
    "# embed each chunk and upsert the embeddings into your pinecone index\n",
    "docsearch = PineconeVectorStore.from_existing_index(\n",
    "    index_name=index_name,\n",
    "    embedding=embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eec423a",
   "metadata": {},
   "source": [
    "adding more data into existing Pinecone Index, if needed code is:\n",
    "\n",
    "dswith = Document(\n",
    "    page_content=\"insert new content\"\n",
    "    metdadata={\"source\": \"source\"}\n",
    ")\n",
    "\n",
    "docsearch.add_documents(documents=[dwsith])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8a631d",
   "metadata": {},
   "source": [
    "### Retriving Text Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a507bc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrive the 3 most relevant chunks\n",
    "retriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac1eda2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='8ee5d76d-5740-44af-91a8-e9ae97153687', metadata={'source': 'ER Wait Time Dataset.csv'}, page_content='On 2024-03-19 23:48:51 at Summit Health Center (Region: Urban),\\n                urgency level was Low.\\n                Total wait time was 100 minutes.\\n                Patient outcome was Admitted.\\n                Patient satisfaction was 1.'),\n",
       " Document(id='0e48a08f-bc3a-49dd-873c-6f8a999e31b9', metadata={'source': 'ER Wait Time Dataset.csv'}, page_content='On 2024-09-17 09:42:50 at Summit Health Center (Region: Urban),\\n                urgency level was Low.\\n                Total wait time was 120 minutes.\\n                Patient outcome was Admitted.\\n                Patient satisfaction was 1.'),\n",
       " Document(id='c641fc04-97a6-4726-ab4e-a8d683600415', metadata={'source': 'ER Wait Time Dataset.csv'}, page_content='On 2024-09-08 15:41:23 at Summit Health Center (Region: Urban),\\n                urgency level was Low.\\n                Total wait time was 120 minutes.\\n                Patient outcome was Admitted.\\n                Patient satisfaction was 1.')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing to see docs retrived\n",
    "retrieved_docs = retriever.invoke(\"what is the satisfaction score of a patient visting Summit Health Center in the Evening on 1/1/12024\")\n",
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7235d32",
   "metadata": {},
   "source": [
    "### creating safe Pandas functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e95f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks type of analytical question\n",
    "def is_analytical_question(question, df):\n",
    "    keywords = [\"average\", \"mean\", \"count\", \"sum\", \"total\", \"min\", \"max\", \"minimum\", \"maximum\", \"number of\"]\n",
    "    if any(k in question.lower() for k in keywords):\n",
    "        return True\n",
    "    # also check if any column is mentioned\n",
    "    for column in df.columns:\n",
    "        if column.lower() in question.lower():\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bca0850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detects the operation needed\n",
    "def detect_operation(question):\n",
    "    q = question.lower()\n",
    "    if \"average\" in q or \"mean\" in q:\n",
    "        return \"mean\"\n",
    "    if \"sum\" in q or \"total\" in q:\n",
    "        return \"sum\"\n",
    "    if \"minimum\" in q or \"min\" in q:\n",
    "        return \"min\"\n",
    "    if \"maximum\" in q or \"max\" in q:\n",
    "        return \"max\"\n",
    "    if \"count\" in q or \"number of\" in q or \"visits\" in q:\n",
    "        return \"count\"\n",
    "    return None\n",
    "\n",
    "# detect the columns used\n",
    "def detect_metric_column(question, df):\n",
    "    q = question.lower()\n",
    "    # common mappings\n",
    "    mapping = {\n",
    "        \"satisfaction\": \"Patient Satisfaction\",\n",
    "        \"customer satisfaction\": \"Patient Satisfaction\",\n",
    "        \"wait\": \"Total Wait Time (min)\",\n",
    "        \"triage\": \"Time to Triage (min)\",\n",
    "        \"registration\": \"Time to Registration (min)\",\n",
    "        \"visit\": \"rows\",\n",
    "        \"number of visits\": \"rows\"\n",
    "    }\n",
    "    for key, column in mapping.items():\n",
    "        if key in q:\n",
    "            return column\n",
    "    # fallback: match any column name partially\n",
    "    for column in df.columns:\n",
    "        words = column.lower().split()\n",
    "        if any(word in q for word in words):\n",
    "            return column\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e38c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computes the dynamic metric\n",
    "def compute_dynamic_metric(df, metric_name, operation, **filters):\n",
    "    filtered = df.copy()\n",
    "    if \"Visit Date\" in df.columns:\n",
    "        filtered[\"Visit Date\"] = pd.to_datetime(filtered[\"Visit Date\"], errors=\"coerce\")\n",
    "\n",
    "    for key, value in filters.items():\n",
    "        if value is None:\n",
    "            continue\n",
    "        if key == \"day\":\n",
    "            filtered = filtered[filtered[\"Visit Date\"].dt.day == value]\n",
    "        elif key == \"month\":\n",
    "            filtered = filtered[filtered[\"Visit Date\"].dt.month == value]\n",
    "        elif key == \"year\":\n",
    "            filtered = filtered[filtered[\"Visit Date\"].dt.year == value]\n",
    "        elif key in filtered.columns:\n",
    "            filtered = filtered[filtered[key] == value]\n",
    "\n",
    "    if len(filtered) == 0:\n",
    "        return None\n",
    "\n",
    "    if metric_name == \"rows\":\n",
    "        return len(filtered)\n",
    "\n",
    "    if metric_name not in filtered.columns:\n",
    "        return None\n",
    "\n",
    "    if operation == \"mean\":\n",
    "        return round(filtered[metric_name].mean(), 2)\n",
    "    if operation == \"sum\":\n",
    "        return round(filtered[metric_name].sum(), 2)\n",
    "    if operation == \"min\":\n",
    "        return filtered[metric_name].min()\n",
    "    if operation == \"max\":\n",
    "        return filtered[metric_name].max()\n",
    "    if operation == \"count\":\n",
    "        return len(filtered)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b1ddeb",
   "metadata": {},
   "source": [
    "### initilaizing <b>chat model and prompts</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "041b22f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatModel = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e491b9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initilize system prompt\n",
    "system_prompt = (\n",
    "    \"You are an analytics assistant for question-answering tasks.\"\n",
    "    \"Use the following pieces of retrieved context to answer\"\n",
    "    \"the question. If you don't know the answer, say that you\"\n",
    "    \"don't know. User three sentences maximum and keep the\"\n",
    "    \"answer concise\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\")\n",
    "\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6cfa9e",
   "metadata": {},
   "source": [
    "### parameters extraction for analytical questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a20953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for chatbot\n",
    "def extract_parameters(question, df):\n",
    "    \"\"\"\n",
    "    Extract filters for any column in df based on question.\n",
    "    Handles dates and categorical fields dynamically.\n",
    "    \"\"\"\n",
    "    params = {}\n",
    "    q_lower = question.lower()\n",
    "\n",
    "    # extarct date (if any)\n",
    "    date_pattern = r'(\\b\\w+\\s+\\d{1,2},?\\s*\\d{4}\\b|\\b\\w+\\s+\\d{4}\\b|\\b\\d{4}\\b)'\n",
    "    date_match = re.search(date_pattern, question)\n",
    "    if date_match:\n",
    "        try:\n",
    "            dt = parser.parse(date_match.group(0))\n",
    "            if re.search(r'\\b\\d{4}\\b', date_match.group(0)):\n",
    "                params[\"year\"] = dt.year\n",
    "            if re.search(r'\\b(jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec|\\d{1,2})\\b', date_match.group(0).lower()):\n",
    "                params[\"month\"] = dt.month\n",
    "            if re.search(r'\\b\\d{1,2},', date_match.group(0)):\n",
    "                params[\"day\"] = dt.day\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # match columns (if any)\n",
    "    for column in df.columns:\n",
    "        if \"date\" in column.lower():\n",
    "            continue\n",
    "        if df[column].dtype == \"object\":\n",
    "            unique_values = df[column].dropna().unique()\n",
    "            for value in unique_values:\n",
    "                if str(value).lower() in q_lower:\n",
    "                    params[column] = value\n",
    "                    break\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4faf9f60",
   "metadata": {},
   "source": [
    "### whole RAG pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e99d5b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all relevant documents into single return prompt for LLM\n",
    "question_answer_chain = create_stuff_documents_chain(chatModel, prompt)\n",
    "# full RAG pipeline (Retrival + Generation)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9931516b",
   "metadata": {},
   "source": [
    "### main chatbot code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee576f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(question):\n",
    "    # attempt analytical computation if applicable\n",
    "    if is_analytical_question(question, df):\n",
    "        filters = extract_parameters(question, df)\n",
    "        operation = detect_operation(question)\n",
    "        metric_name = detect_metric_column(question, df)\n",
    "\n",
    "        # if count\n",
    "        if operation == \"count\" and metric_name is None:\n",
    "            metric_name = \"rows\"\n",
    "\n",
    "        if operation and metric_name:\n",
    "            result = compute_dynamic_metric(df, metric_name, operation, **filters)\n",
    "            if result is not None:\n",
    "                return f\"The {operation} of {metric_name if metric_name != 'rows' else 'records'} is {result}.\"\n",
    "\n",
    "    # fallback to RAG if analytical fails\n",
    "    response = rag_chain.invoke({\"input\": question})\n",
    "    return response[\"answer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1117e54f",
   "metadata": {},
   "source": [
    "#### Testing of Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5d07c922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of Patient Satisfaction is 2.47.\n"
     ]
    }
   ],
   "source": [
    "# question 1\n",
    "question = \"What is the average customer satisfaction score for Summit Health Center in Jan 2024?\"\n",
    "answer = chatbot(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "45e31b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The count of records is 23.\n"
     ]
    }
   ],
   "source": [
    "# question 2\n",
    "question = \"What is the patient visit count on April 4, 2024\"\n",
    "answer = chatbot(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "78844a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The count of records is 1258.\n"
     ]
    }
   ],
   "source": [
    "# question 3\n",
    "question = \"Visit count during Winter\"\n",
    "answer = chatbot(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f402140f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Riverside Medical Center is in an urban region.\n"
     ]
    }
   ],
   "source": [
    "# question 4\n",
    "question = \"What region is Riverside Hospital in?\"\n",
    "answer = chatbot(question)\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
